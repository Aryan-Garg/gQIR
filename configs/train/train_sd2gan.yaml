output_dir: /home/argar/apgi/gQVR/experiments


dataset:
  train:
    batch_size: 2
    dataloader_num_workers: 96
    target: gqvr.dataset.spc_image_only.SPCDataset
    params:
      file_list: /mnt/disks/behemoth/datasets/dataset_txt_files/combined_dataset.txt
      file_backend_cfg:
        target: gqvr.dataset.file_backend.HardDiskBackend
      out_size: 512
      crop_type: "center"
      use_hflip: False
    batch_transform:
      target: gqvr.dataset.batch_transform.IdentityBatchTransform

  val:
    batch_size: 1
    dataloader_num_workers: 96
    target: gqvr.dataset.spc_image_only.SPCDataset
    params:
      file_list: /mnt/disks/behemoth/datasets/dataset_txt_files/random_val.txt
      file_backend_cfg:
        target: gqvr.dataset.file_backend.HardDiskBackend
      out_size: 512
      crop_type: "center"
      use_hflip: False
    batch_transform:
      target: gqvr.dataset.batch_transform.IdentityBatchTransform

# qVAE config:    
model:
  vae_cfg:
    embed_dim: 4
    ddconfig:
      double_z: true
      z_channels: 4
      resolution: 512
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 2
      - 4
      - 4
      num_res_blocks: 2
      attn_resolutions: []
      dropout: 0.0


base_model_type: sd2
base_model_path: ByteDance/sd2.1-base-zsnr-laionaes5
qvae_path: /home/argar/apgi/gQVR/experiments/3bit_vae_10xlr_8xBS/0600000.pt
model_t: 200
coeff_t: 200
lora_rank: 256
lora_modules: [to_k, to_q, to_v, to_out.0, conv, conv1, conv2, conv_shortcut, conv_out, proj_in, proj_out, ff.net.2, ff.net.0.proj]
use_ema: true
ema_decay: 0.999
resume_ema: true

lambda_gan: 0.5
lambda_lpips: 5
lambda_l2: 1
lr_G: 1e-5
lr_D: 1e-5
optimizer_type: adam
opt_kwargs:
  betas: [0.9, 0.999]

mixed_precision: bf16
seed: 310
max_train_steps: 3000000
gradient_accumulation_steps: 4
gradient_checkpointing: true
max_grad_norm: 1.0
logging_dir: logs
report_to: tensorboard
checkpointing_steps: 500
checkpoints_total_limit: None
resume_from_checkpoint: ~
log_image_steps: 250
log_grad_steps: 250
log_grad_modules: [conv_out]