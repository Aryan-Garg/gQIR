model:
  vae_cfg:
    embed_dim: 4
    ddconfig:
      double_z: true
      z_channels: 4
      resolution: 512
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 2
      - 4
      - 4
      num_res_blocks: 2
      attn_resolutions: []
      dropout: 0.0


dataset:
  train:
    target: gqvr.dataset.spc_image_only.SPCDataset
    params:
      file_list: /media/agarg54/Extreme SSD/dataset_files/combined_dataset.txt
      file_backend_cfg:
        target: gqvr.dataset.file_backend.HardDiskBackend
      out_size: 512
      crop_type: "center"
      use_hflip: False
  val:
    target: gqvr.dataset.spc_image_only.SPCDataset
    params:
      file_list: /media/agarg54/Extreme SSD/dataset_txt_files/full_test_set.txt
      file_backend_cfg:
        target: gqvr.dataset.file_backend.HardDiskBackend
      out_size: 512
      crop_type: "center"
      use_hflip: False


batch_transform:
  target: gqvr.dataset.batch_transform.IdentityBatchTransform
  # params:

train:
  # pretrained sd v2.1-zsnr path
  sd_path: "/media/agarg54/Extreme SSD/weights/gqvr_sd21/3bit_vae_10xlr_8xBS/0600000.pt"
  # experiment directory path
  exp_dir: "/nobackup1/aryan/weights/continue_VAE_UA"
  learning_rate: 1e-5
  batch_size: 1
  num_workers: 32
  train_steps: 3_000_000
  log_every: 500
  ckpt_every: 1000
  image_every: 200
  val_every: 500
  # Loss params
  loss_mode: "mse_ls_gt_perceptual" # "mse_ls", "ls_only", "ls_gt", "ls_gt_perceptual"
  loss_scales:
    lsa: 0.1
    mse: 1000.
    gt: 100.
    perceptual: 2.
