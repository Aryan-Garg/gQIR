output_dir: /home/argar/apgi/gQVR/experiments_video

dataset:
  batch_transform:
      target: gqvr.dataset.batch_transform.IdentityBatchTransform
  train:
    batch_size: 1
    dataloader_num_workers: 96
    target: gqvr.dataset.spc_video.SPCVideoDataset
    params:
      file_list: /mnt/disks/behemoth/datasets/video_dataset_txt_files/combined_video_dataset.txt
      file_backend_cfg:
        target: gqvr.dataset.file_backend.HardDiskBackend
      out_size: 512
      crop_type: "center"
      use_hflip: False
      precomputed_latents: True

  val:
    batch_size: 1
    dataloader_num_workers: 96
    target: gqvr.dataset.spc_video.SPCVideoDataset
    params:
      file_list: /mnt/disks/behemoth/datasets/video_dataset_txt_files/random_video_val.txt
      file_backend_cfg:
        target: gqvr.dataset.file_backend.HardDiskBackend
      out_size: 512
      crop_type: "center"
      use_hflip: False
      precomputed_latents: True
    batch_transform:
      target: gqvr.dataset.batch_transform.IdentityBatchTransform

# qVAE * temp config:    
model:
  temp_cfg:
    z_channels: 4
    z_resolution: 64
    # heads:  

  vae_cfg:
    embed_dim: 4
    ddconfig:
      double_z: true
      z_channels: 4
      resolution: 512
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 2
      - 4
      - 4
      num_res_blocks: 2
      attn_resolutions: []
      dropout: 0.0

prompt_training: false
lifting_training: true
qvae_path: /home/argar/apgi/gQVR/experiments/3bit_vae_10xlr_8xBS/0600000.pt

# Loss params
loss_mode: "l1_flow_perceptual" # "flow" must | optional: ["l1", "perceptual"] 
loss_scales:
  l1: 1.
  perceptual: 5.
  flow: 10.


lr_temp_stabilizer: 1e-5
optimizer_type: adam
opt_kwargs:
  betas: [0.9, 0.999]

mixed_precision: bf16
seed: 310
max_train_steps: 50000
checkpointing_steps: 1000
checkpoints_total_limit: None
resume_from_checkpoint: ~
log_image_steps: 500
log_every: 1000
val_every: 5000