{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a55ffee",
   "metadata": {},
   "source": [
    "## Test All Things Flow for Stage 3 before training!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66c03b2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8474bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from model.core_raft.raft import RAFT\n",
    "from model.core_raft.utils import flow_viz\n",
    "from model.core_raft.utils.utils import InputPadder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f7fa0f",
   "metadata": {},
   "source": [
    "### Video Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193cb3e",
   "metadata": {},
   "source": [
    "### Compute RAFT Flow & Viz (Using pipeline implemented code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60662259",
   "metadata": {},
   "source": [
    "### Test Differentiable Warping & Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd27c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def differentiable_warp(x, flow):\n",
    "    \"\"\"\n",
    "    Warp image or feature x according to flow.\n",
    "    x: [B, C, H, W]\n",
    "    flow: [B, 2, H, W] (flow in pixels, with flow[:,0] = dx, flow[:,1] = dy)\n",
    "    \"\"\"\n",
    "    B, C, H, W = x.size()\n",
    "    # Create mesh grid normalized to [-1,1]\n",
    "    grid_y, grid_x = torch.meshgrid(torch.arange(H), torch.arange(W))\n",
    "    grid = torch.stack((grid_x, grid_y), 2).float().to(x.device)  # [H, W, 2]\n",
    "\n",
    "    grid = grid.unsqueeze(0).repeat(B, 1, 1, 1)  # [B, H, W, 2]\n",
    "\n",
    "    # Add flow, normalize grid to [-1,1]\n",
    "    flow = flow.permute(0, 2, 3, 1)\n",
    "    new_grid = grid + flow\n",
    "    new_grid[..., 0] = 2.0 * new_grid[..., 0] / (W - 1) - 1.0\n",
    "    new_grid[..., 1] = 2.0 * new_grid[..., 1] / (H - 1) - 1.0\n",
    "\n",
    "    warped = F.grid_sample(x, new_grid, align_corners=True)\n",
    "    return warped\n",
    "\n",
    "\n",
    "def compute_flow_magnitude(flow):\n",
    "    return torch.norm(flow, dim=1, keepdim=True)  # [B, 1, H, W]\n",
    "\n",
    "def compute_flow_gradients(flow):\n",
    "    # flow: [B, 2, H, W]\n",
    "    fx = flow[:, 0:1, :, :]  # horizontal flow\n",
    "    fy = flow[:, 1:2, :, :]  # vertical flow\n",
    "\n",
    "    # finite difference gradients (simple Sobel or central differences)\n",
    "    fx_du = fx[:, :, :, 2:] - fx[:, :, :, :-2]  # d/dx\n",
    "    fx_dv = fx[:, :, 2:, :] - fx[:, :, :-2, :]  # d/dy\n",
    "\n",
    "    fy_du = fy[:, :, :, 2:] - fy[:, :, :, :-2]\n",
    "    fy_dv = fy[:, :, 2:, :] - fy[:, :, :-2, :]\n",
    "\n",
    "    # pad to original size (pad 1 pixel on each side)\n",
    "    fx_du = F.pad(fx_du, (1, 1, 0, 0))\n",
    "    fx_dv = F.pad(fx_dv, (0, 0, 1, 1))\n",
    "    fy_du = F.pad(fy_du, (1, 1, 0, 0))\n",
    "    fy_dv = F.pad(fy_dv, (0, 0, 1, 1))\n",
    "\n",
    "    return fx_du, fx_dv, fy_du, fy_dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warp_utils import flow_to_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065084ca",
   "metadata": {},
   "source": [
    "### Test Differentiable Occlusion Mask Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63a23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_occlusion(fw_flow, bw_flow, img):\n",
    "    \"\"\"\n",
    "    fw_flow: forward flow from img1 to img2, [B, 2, H, W]\n",
    "    bw_flow: backward flow from img2 to img1, [B, 2, H, W]\n",
    "    img: image tensor (for warping), [B, C, H, W]\n",
    "\n",
    "    Returns:\n",
    "        occlusion mask [B, 1, H, W], float tensor (0 or 1 mask)\n",
    "        warped_img2: img warped back to img1 space by bw_flow\n",
    "    \"\"\"\n",
    "\n",
    "    # Warp forward flow to img2 frame using backward flow\n",
    "    fw_flow_warped = differentiable_warp(fw_flow, bw_flow)  # [B, 2, H, W]\n",
    "\n",
    "    # Warp img to img1 space using backward flow\n",
    "    warp_img = differentiable_warp(img, bw_flow)\n",
    "\n",
    "    # Forward-backward flow consistency check\n",
    "    fb_flow_sum = fw_flow_warped + bw_flow  # should be near zero if consistent\n",
    "\n",
    "    fb_flow_mag = compute_flow_magnitude(fb_flow_sum)  # [B,1,H,W]\n",
    "    fw_flow_w_mag = compute_flow_magnitude(fw_flow_warped)\n",
    "    bw_flow_mag = compute_flow_magnitude(bw_flow)\n",
    "\n",
    "    threshold = 0.01 * (fw_flow_w_mag + bw_flow_mag) + 0.5\n",
    "\n",
    "    mask1 = fb_flow_mag > threshold  # bool mask [B,1,H,W]\n",
    "\n",
    "    # Compute flow gradients for motion boundary detection\n",
    "    fx_du, fx_dv, fy_du, fy_dv = compute_flow_gradients(bw_flow)\n",
    "    fx_mag = fx_du ** 2 + fx_dv ** 2\n",
    "    fy_mag = fy_du ** 2 + fy_dv ** 2\n",
    "\n",
    "    mask2 = (fx_mag + fy_mag) > 0.01 * bw_flow_mag + 0.002\n",
    "\n",
    "    # Combine masks\n",
    "    mask = mask1 | mask2  # logical or\n",
    "\n",
    "    occlusion = mask.float()  # convert to float mask (0 or 1)\n",
    "\n",
    "    return occlusion, warp_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a87e0ed",
   "metadata": {},
   "source": [
    "### Is Differentiable Warp loss ~= E*_warp loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f698584",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "star",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
